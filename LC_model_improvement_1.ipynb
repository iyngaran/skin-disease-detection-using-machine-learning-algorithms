{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyMcxgh97gycBYLNFc5JcbEh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iyngaran/skin-disease-detection-using-machine-learning-algorithms/blob/master/LC_model_improvement_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Steps\n",
        "\n",
        "\n",
        "\n",
        "1.   Download the lesion-diagnosis Dataset and unzip it clone the git repo which has a utility function to generate images for training and testing.\n",
        "2.   Prepare datasets for train and test.\n",
        "3.   Visualize the images\n",
        "4.   Building a convolutional neural network\n",
        "     1.   Preprocess / normalize the images \n",
        "     2.   Load all the images\n",
        "     3.   Build a CNN to find patterns in the images\n",
        "     4.   Compile our CNN\n",
        "     5.   Fit the CNN to our training data\n",
        "     6.   Visualise the training results\n",
        "     7.   Recreate the model again and compile it and train\n"
      ],
      "metadata": {
        "id": "UYVE5fPB6QV_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Download the lesion-diagnosis Dataset and unzip it clone the git repo which has a utility function to generate images for training and testing."
      ],
      "metadata": {
        "id": "apUkl8_il5Zu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bf2A_h786K7j"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "#os.system(\"rm -rf ipythonUtils\")\n",
        "#os.system(\"rm -rf lesion-diagnosis\")\n",
        "#os.system(\"rm -rf lesion-diagnosis-ver2.zip\")\n",
        "#os.system(\"rm -rf test\")\n",
        "#os.system(\"rm -rf train\")\n",
        "\n",
        "isExist = os.path.exists(\"ipython-utils\")\n",
        "if not os.path.exists(\"ipython-utils\"):\n",
        "    !git clone https://github.com/iyngaran/ipythonUtils.git\n",
        "\n",
        "\n",
        "if not os.path.exists(\"lesion-diagnosis-ver2.zip\"):\n",
        "    !wget  https://testing.idev55.com/lesion-diagnosis-ver2.zip\n",
        "\n",
        "if not os.path.exists(\"lesion-diagnosis\"):\n",
        "    # Unzip the downloaded file\n",
        "    zip_file = zipfile.ZipFile(\"lesion-diagnosis-ver2.zip\", \"r\")\n",
        "    zip_file.extractall()\n",
        "    zip_file.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Walk through pizza_steak directory and list number of files\n",
        "for dirpath, dirnames, filenames in os.walk(\"lesion-diagnosis\"):\n",
        "  print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")"
      ],
      "metadata": {
        "id": "Ovyr7g3AwkVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**To Balance the data in all the classes, let's use `Augmentor` with `flip_top_bottom` and `zoom` to generate images**"
      ],
      "metadata": {
        "id": "zmLr6eYntPD4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Augmentor"
      ],
      "metadata": {
        "id": "V-mikKQV4sNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import Augmentor\n",
        "p = Augmentor.Pipeline(\"lesion-diagnosis/solar-lentigo\")\n",
        "p.flip_top_bottom(probability=0.8)\n",
        "p.zoom(probability=0.3, min_factor=1.1, max_factor=1.6)\n",
        "p.sample(570) ## We are adding 570 samples.\n",
        "\n",
        "p = Augmentor.Pipeline(\"lesion-diagnosis/vascular-lesion\")\n",
        "p.flip_top_bottom(probability=0.8)\n",
        "p.zoom(probability=0.3, min_factor=1.1, max_factor=1.6)\n",
        "p.sample(739) ## We are adding 739 samples.\n",
        "\n",
        "p = Augmentor.Pipeline(\"lesion-diagnosis/dermatofibroma\")\n",
        "p.flip_top_bottom(probability=0.8)\n",
        "p.zoom(probability=0.3, min_factor=1.1, max_factor=1.6)\n",
        "p.sample(745) ## We are adding 745 samples.\n",
        "\n",
        "\n",
        "p = Augmentor.Pipeline(\"lesion-diagnosis/squamous-cell-carcinoma\")\n",
        "p.flip_top_bottom(probability=0.8)\n",
        "p.zoom(probability=0.3, min_factor=1.1, max_factor=1.6)\n",
        "p.sample(323) ## We are adding 323 samples.\n",
        "\n",
        "p = Augmentor.Pipeline(\"lesion-diagnosis/actinic-keratosis\")\n",
        "p.flip_top_bottom(probability=0.8)\n",
        "p.zoom(probability=0.3, min_factor=1.1, max_factor=1.6)\n",
        "p.sample(88) ## We are adding 88 samples per class."
      ],
      "metadata": {
        "id": "NvDH2qMz-ILG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv lesion-diagnosis/solar-lentigo/output/* lesion-diagnosis/solar-lentigo/\n",
        "!mv lesion-diagnosis/vascular-lesion/output/* lesion-diagnosis/vascular-lesion/\n",
        "!mv lesion-diagnosis/dermatofibroma/output/* lesion-diagnosis/dermatofibroma/\n",
        "!mv lesion-diagnosis/squamous-cell-carcinoma/output/* lesion-diagnosis/squamous-cell-carcinoma/\n",
        "!mv lesion-diagnosis/actinic-keratosis/output/* lesion-diagnosis/actinic-keratosis/\n",
        "\n",
        "\n",
        "!rm -rf lesion-diagnosis/solar-lentigo/output\n",
        "!rm -rf lesion-diagnosis/vascular-lesion/output\n",
        "!rm -rf lesion-diagnosis/dermatofibroma/output\n",
        "!rm -rf lesion-diagnosis/squamous-cell-carcinoma/output\n",
        "!rm -rf lesion-diagnosis/actinic-keratosis/output"
      ],
      "metadata": {
        "id": "TZ72C_po-xGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for dirpath, dirnames, filenames in os.walk(\"lesion-diagnosis\"):\n",
        "  print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")"
      ],
      "metadata": {
        "id": "gKEPCBHy5nm-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " we can see here, all the classes have the same number of images"
      ],
      "metadata": {
        "id": "IiP_OiiBt0L8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Prepare datasets for train and test \n",
        "\n",
        "Generate test and train datasets using the `generate_test_and_train_datasets` utility function"
      ],
      "metadata": {
        "id": "WX-JJQqqmMcc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ipythonUtils.generateTestTrain import generate_test_and_train_datasets\n",
        "if not os.path.exists(\"train/actinic-keratosis\"):\n",
        "   generate_test_and_train_datasets()"
      ],
      "metadata": {
        "id": "tDSsOZU1WlZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Turn our training path into a Python path and created a list of class_names from the subdirectories"
      ],
      "metadata": {
        "id": "MDkrmJH0oYkg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "import numpy as np\n",
        "\n",
        "data_dir = pathlib.Path(\"train\") \n",
        "class_names = np.array(sorted([item.name for item in data_dir.glob('*')]))\n",
        "print(class_names)"
      ],
      "metadata": {
        "id": "ZKeWq96LoQne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls train"
      ],
      "metadata": {
        "id": "cW3ASuoQozEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Setup the train and test directories**"
      ],
      "metadata": {
        "id": "DXd7OYvNo9xs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir_train = pathlib.Path(\"train\")\n",
        "data_dir_test = pathlib.Path(\"test\")"
      ],
      "metadata": {
        "id": "EcDfZfKbpCwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_count_train = len(list(data_dir_train.glob('*/*.JPG')))\n",
        "image_count_test = len(list(data_dir_test.glob('*/*.JPG')))\n",
        "image_count_train, image_count_test"
      ],
      "metadata": {
        "id": "H1Iu6XR5pMkj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Visualize the images"
      ],
      "metadata": {
        "id": "ZYGPjo4wqI4A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ipythonUtils.generateTestTrain import view_random_image\n",
        "img = view_random_image(target_dir=\"train\", target_class=\"melanoma\")"
      ],
      "metadata": {
        "id": "CZG2slMAqKx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img2 = view_random_image(target_dir=\"test\", target_class=\"nevus\")"
      ],
      "metadata": {
        "id": "EQEUx4SNu2EK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img.shape, img2.shape"
      ],
      "metadata": {
        "id": "bGNts5xbvIuG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4.   Building a convolutional neural network"
      ],
      "metadata": {
        "id": "7fjtPfBDvUNp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.1 Preprocess / normalize the images"
      ],
      "metadata": {
        "id": "TUjjURZBvY2n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "img_height = 180\n",
        "img_width = 180\n",
        "num_classes = len(class_names)"
      ],
      "metadata": {
        "id": "vyRyD9yCvVqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "## create train dataset\n",
        "\n",
        "## get all the train images and resizing them to the size of img_height*img_width and create batches\n",
        "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    data_dir_train,\n",
        "    seed=123,\n",
        "    validation_split = 0.2,\n",
        "    subset='training',\n",
        "    image_size=(img_height, img_width),  \n",
        "    batch_size=batch_size)"
      ],
      "metadata": {
        "id": "5qzWQi7hvxiZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## create validation dataset\n",
        "val_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    data_dir_train,\n",
        "    seed=123,\n",
        "    validation_split = 0.2,\n",
        "    subset='validation',\n",
        "    image_size=(img_height, img_width),  \n",
        "    batch_size=batch_size)"
      ],
      "metadata": {
        "id": "rtgUElCkv4sM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**See the classes distribution**"
      ],
      "metadata": {
        "id": "NKMBodjx0Y3_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load all the images - Randomly select an image from each classes and display them.**"
      ],
      "metadata": {
        "id": "RxFIJ_l3puL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_dataset.take(1):\n",
        "  for i in range(len(class_names)-1):\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(img)\n",
        "    plt.title(class_names[labels[i]])\n",
        "    plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "n524Ee1_0amX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cache DataSet**\n",
        "\n",
        "Keeps the images in memory using `Dataset.cache()` -  after images are loaded off disk during the first epoch.\n",
        "\n",
        "Overlaps data preprocessing and model execution while training - `Dataset.prefetch().`"
      ],
      "metadata": {
        "id": "nSWD301Wqy_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "train_dataset = train_dataset.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "val_dataset = val_dataset.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "sG8LRApLq4YE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.3 Build a CNN to find patterns in the images"
      ],
      "metadata": {
        "id": "l97jyHbrrEfs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "model = Sequential([\n",
        "  layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(num_classes)\n",
        "])"
      ],
      "metadata": {
        "id": "uwLLSm8vrJPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.4 Compile our CNN"
      ],
      "metadata": {
        "id": "NPHvBI23rRdR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "wnkbdfy5rQ-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View the summary of all layers\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "0WKrUvLVra0n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.5 Fit the CNN to our training data"
      ],
      "metadata": {
        "id": "T7w3aXlkrjay"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 20\n",
        "history = model.fit(\n",
        "  train_dataset,\n",
        "  validation_data=val_dataset,\n",
        "  epochs=epochs\n",
        ")"
      ],
      "metadata": {
        "id": "zH1Ragd-rlBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.6 Visualizing training results"
      ],
      "metadata": {
        "id": "XXGTQyVCuxW4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_accuracy, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GQzacv1luyoR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see here that the training accuracy has improved a lot however, the validation accuracy hasn’t improve much. It means the model is overfitting and it is not able to generalise well.\n",
        "\n",
        "Similarly, the training loss is falling down and validation loss is increasing dramatically.\n",
        "\n",
        "To overcome this problem, I am going to use augmentation technique. I am going to generate new samples by modifying the existing training data and use them t0 train the model.\n"
      ],
      "metadata": {
        "id": "uABx6zKpv4ow"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation = keras.Sequential([\n",
        "      layers.experimental.preprocessing.RandomFlip(\"horizontal\", input_shape=(img_height, img_width, 3)),\n",
        "      layers.experimental.preprocessing.RandomRotation(0.1),\n",
        "      layers.experimental.preprocessing.RandomZoom(0.1),\n",
        "])"
      ],
      "metadata": {
        "id": "tn7QN8Pr9qiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from glob import glob\n",
        "path_list = [ x for x in glob(os.path.join(data_dir_train, '*', '*.JPG')) ] \n",
        "lesion_list = [ os.path.basename(os.path.dirname(y)) for y in glob(os.path.join(data_dir_train, '*', '*.JPG')) ]\n",
        "print(len(lesion_list))"
      ],
      "metadata": {
        "id": "uRUh9XTP8Ha6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_dict_original = dict(zip(path_list, lesion_list))\n",
        "list(df_dict_original.items())[:2]"
      ],
      "metadata": {
        "id": "F9Pt99t58JdP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "original_df = pd.DataFrame(list(df_dict_original.items()), columns=['Path','Label'])\n",
        "original_df.head()"
      ],
      "metadata": {
        "id": "ndwyeTPo8NRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_df[['Label']].value_counts()"
      ],
      "metadata": {
        "id": "FNfN3Qs08UDo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_df[['Label']].value_counts(normalize=True)"
      ],
      "metadata": {
        "id": "EdeUroXm8V6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_training_dataset=str(data_dir_train) + '/'\n",
        "import Augmentor\n",
        "for i in class_names:\n",
        "    p = Augmentor.Pipeline(path_to_training_dataset + i)\n",
        "    p.rotate(probability=0.7, max_left_rotation=10, max_right_rotation=10)\n",
        "    p.sample(1000) ## We are adding 1000 samples per class."
      ],
      "metadata": {
        "id": "YlBglzBOv8I4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_train_images = len(list(data_dir_train.glob('*/output/*.JPG')))\n",
        "print(total_train_images)"
      ],
      "metadata": {
        "id": "09xcHMyiwtas"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's see the distribution of augmented data.**"
      ],
      "metadata": {
        "id": "1ZR7ZJK77PVX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from glob import glob\n",
        "path_list_new = [x for x in glob(os.path.join(data_dir_train, '*','output', '*.JPG'))]\n",
        "path_list_new[:2]"
      ],
      "metadata": {
        "id": "J3-tCSbd7QHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lesion_list_new = [os.path.basename(os.path.dirname(os.path.dirname(y))) for y in glob(os.path.join(data_dir_train, '*','output', '*.JPG'))]\n",
        "lesion_list_new[:2]"
      ],
      "metadata": {
        "id": "jg8fKvsk7xcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "dataframe_dict_new = dict(zip(path_list_new, lesion_list_new))\n",
        "\n",
        "df_2 = pd.DataFrame(list(dataframe_dict_new.items()),columns = ['Path','Label'])\n",
        "new_df = original_df.append(df_2)\n",
        "new_df.shape"
      ],
      "metadata": {
        "id": "Klc46FoL71_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df.head()"
      ],
      "metadata": {
        "id": "veLm0c_U8f3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the class distribution after adding the new images\n",
        "new_df['Label'].value_counts(normalize=True)"
      ],
      "metadata": {
        "id": "JB5t1IM78vZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df['Label'].value_counts()"
      ],
      "metadata": {
        "id": "GpUL9maZ8yUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Again : Train the model with complete dataset (including newly created images using Augmentor)**"
      ],
      "metadata": {
        "id": "pOJlbukm83d_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create a training dataset**"
      ],
      "metadata": {
        "id": "BPTeIBpH868U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data_dir_train=\"path to directory with training data + data created using augmentor\"\n",
        "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir_train,\n",
        "  seed=123,\n",
        "  validation_split = 0.2,\n",
        "  subset = 'training',\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "metadata": {
        "id": "lCJDYnwP877u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create a validation dataset**"
      ],
      "metadata": {
        "id": "YvLp0B2X9B_f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir_train,\n",
        "  seed=123,\n",
        "  validation_split = 0.2,\n",
        "  subset = 'validation',\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "metadata": {
        "id": "pMhTYQQH9ELd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Recreate the model again**"
      ],
      "metadata": {
        "id": "SEKilBuj9KcQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "  data_augmentation,\n",
        "  layers.experimental.preprocessing.Rescaling(1./255),\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Dropout(0.2),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(num_classes)\n",
        "])"
      ],
      "metadata": {
        "id": "Gqr_rFvm9I_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "ULgg4x999y1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 30\n",
        "\n",
        "history = model.fit(\n",
        "  train_dataset,\n",
        "  validation_data=val_dataset,\n",
        "  epochs=epochs\n",
        ")"
      ],
      "metadata": {
        "id": "AxnsSd1g90Vg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Visualize the model results**"
      ],
      "metadata": {
        "id": "s7Sf4I4cRBHY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_accuracy, label='Validation Accuracy')\n",
        "plt.legend(loc='upper left')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FNJUPc7aQ6Jn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Making a prediction with our trained model"
      ],
      "metadata": {
        "id": "hA3kZAcfRJqP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.image as mpimg\n",
        "\n",
        "!wget https://goldencoastdermatology.com/wp-content/uploads/2020/02/ACTINIC-KERATOSES.jpg\n",
        "actinic_keratosis = mpimg.imread(\"ACTINIC-KERATOSES.jpg\")\n",
        "plt.imshow(actinic_keratosis)\n",
        "plt.axis(False);"
      ],
      "metadata": {
        "id": "hekkqnH2RK98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a function to import an image and resize it to be able to be used with our model\n",
        "def load_and_prep_image(filename, img_shape=180):\n",
        "  \"\"\"\n",
        "  Reads an image from filename, turns it into a tensor\n",
        "  and reshapes it to (img_shape, img_shape, colour_channel).\n",
        "  \"\"\"\n",
        "  # Read in target file (an image)\n",
        "  img = tf.io.read_file(filename)\n",
        "\n",
        "  # Decode the read file into a tensor & ensure 3 colour channels \n",
        "  # (our model is trained on images with 3 colour channels and sometimes images have 4 colour channels)\n",
        "  img = tf.image.decode_image(img, channels=3)\n",
        "\n",
        "  # Resize the image (to the same size our model was trained on)\n",
        "  img = tf.image.resize(img, size = [img_shape, img_shape])\n",
        "\n",
        "  # Rescale the image (get all values between 0 and 1)\n",
        "  img = img/255.\n",
        "  return img"
      ],
      "metadata": {
        "id": "8WFpJ00MRafe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in and preprocess our custom image\n",
        "actinic_keratosis = load_and_prep_image(\"ACTINIC-KERATOSES.jpg\")\n",
        "actinic_keratosis"
      ],
      "metadata": {
        "id": "5lMj-AunRe3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add an extra axis\n",
        "print(f\"Shape before new dimension: {actinic_keratosis.shape}\")\n",
        "actinic_keratosis = tf.expand_dims(actinic_keratosis, axis=0) # add an extra dimension at axis 0\n",
        "print(f\"Shape after new dimension: {actinic_keratosis.shape}\")\n",
        "actinic_keratosis"
      ],
      "metadata": {
        "id": "7ldsU-cKRi9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model.predict(actinic_keratosis)\n",
        "pred"
      ],
      "metadata": {
        "id": "RrsjQbdkRmM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_class = class_names[int(tf.round(pred)[0][0])]\n",
        "pred_class"
      ],
      "metadata": {
        "id": "AK_DoIHDRpvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pred_and_plot(model, filename, class_names):\n",
        "  \"\"\"\n",
        "  Imports an image located at filename, makes a prediction on it with\n",
        "  a trained model and plots the image with the predicted class as the title.\n",
        "  \"\"\"\n",
        "  # Import the target image and preprocess it\n",
        "  img = load_and_prep_image(filename)\n",
        "\n",
        "  # Make a prediction\n",
        "  pred = model.predict(tf.expand_dims(img, axis=0))\n",
        "\n",
        "  # Get the predicted class\n",
        "  pred_class = class_names[int(tf.round(pred)[0][0])]\n",
        "\n",
        "  # Plot the image and predicted class\n",
        "  plt.imshow(img)\n",
        "  plt.title(f\"Prediction: {pred_class}\")\n",
        "  plt.axis(False);"
      ],
      "metadata": {
        "id": "tjerenAfRud4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test our model on a custom image\n",
        "pred_and_plot(model, \"ACTINIC-KERATOSES.jpg\", class_names)"
      ],
      "metadata": {
        "id": "qBPyyBtLRyNV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}